{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5c2db3c-570a-4520-97f9-e99b7cce1377",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67358494-16f1-4179-9182-986945b729c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# load pipeline and step parameters - do not edit\n",
    "from sinara.substep import get_pipeline_params, get_step_params\n",
    "pipeline_params = get_pipeline_params(pprint=True)\n",
    "step_params = get_step_params(pprint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca2677e-6dbf-49cb-94cf-55ab34553123",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# specify substep parameters for interactive run\n",
    "# this cell will be replaced during job run with the parameters from json within params subfolder\n",
    "substep_params={\n",
    "    'save_best': False,\n",
    "    'device': \"cuda:0\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa0a075-eca9-4b7a-ab12-457a84f5dbb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define substep interface\n",
    "from sinara.substep import NotebookSubstep, ENV_NAME, PIPELINE_NAME, ZONE_NAME, STEP_NAME, RUN_ID, ENTITY_NAME, ENTITY_PATH, SUBSTEP_NAME\n",
    "\n",
    "substep = NotebookSubstep(pipeline_params, step_params, substep_params)\n",
    "\n",
    "substep.interface(\n",
    "    inputs =\n",
    "    [ \n",
    "      { STEP_NAME: \"model_train\", ENTITY_NAME: \"classifier_inference_files\"}, # stored detector files from train step\n",
    "      { STEP_NAME: \"data_load\", ENTITY_NAME: \"meta_cifar10_datasets\"} # meta information of dataset from data_load step\n",
    "    ],\n",
    "    \n",
    "    tmp_entities =\n",
    "    [\n",
    "        { ENTITY_NAME: \"classifier_inference_files\" }, # temporary detector files from train step\n",
    "        { ENTITY_NAME: \"classifier_onnx_files\"}, # temporary detector onnx files after converting \n",
    "        { ENTITY_NAME: \"meta_cifar10_datasets\"} # extracted temporary meta information of dataset from data_load step\n",
    "    ],\n",
    "    \n",
    "    outputs =\n",
    "    [\n",
    "        { ENTITY_NAME: \"bento_service\" } # stored BentoService\n",
    "    ],\n",
    ")\n",
    "\n",
    "substep.print_interface_info()\n",
    "\n",
    "substep.exit_in_visualize_mode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6114cb21-c454-4066-bdf1-b661d623e98c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# specify all notebook wide libraries imports here\n",
    "# Sinara lib imports is left in the place of their usage\n",
    "import json\n",
    "import os\n",
    "import os.path as osp\n",
    "import glob\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import onnxruntime, pickle, shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971a55f1-6203-46b0-89f9-aed0cafb18f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# run spark\n",
    "from sinara.spark import SinaraSpark\n",
    "from sinara.archive import SinaraArchive\n",
    "\n",
    "spark = SinaraSpark.run_session(0)\n",
    "archive = SinaraArchive(spark)\n",
    "SinaraSpark.ui_url()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ea64bc-5c73-4766-b3a0-6bad6c94caf1",
   "metadata": {},
   "source": [
    "### Loading classifier inference files from the model_train step \n",
    "(weights, configs, test image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2060677f-4ae3-451c-8122-af898fd754a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_train_inputs = substep.inputs(step_name = \"model_train\")\n",
    "data_load_inputs = substep.inputs(step_name = \"data_load\")\n",
    "tmp_entities = substep.tmp_entities()\n",
    "# copy config from previos step to outputs\n",
    "\n",
    "archive.unpack_files_from_store_to_tmp(store_path=model_train_inputs.classifier_inference_files, tmp_dir=tmp_entities.classifier_inference_files)\n",
    "archive.unpack_files_from_store_to_tmp(store_path=data_load_inputs.meta_cifar10_datasets, tmp_dir=tmp_entities.meta_cifar10_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cccaf57-5e98-40fd-98d1-e9b6b58c788a",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Select obj_detector weights for converting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae96ad73-dabb-478c-a2d1-488f78b77761",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selecting a weights file to convert to onnx format (best, latest epoch, etc.)\n",
    "best_weights_pths = glob.glob(f\"{tmp_entities.classifier_inference_files}/*best*\")\n",
    "latest_weights_pths = glob.glob(f\"{tmp_entities.classifier_inference_files}/*latest*\")\n",
    "\n",
    "weights_pths = best_weights_pths if substep_params['save_best'] and len(best_weights_pths) > 0 else latest_weights_pths\n",
    "\n",
    "weights_pths.sort(key=lambda file: osp.getmtime(file))\n",
    "\n",
    "selected_weights_pth = weights_pths[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed8cec8-21f2-4607-b7ad-49310164c9f8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Export to ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2561d7dc-c852-4349-9eeb-0c0e24350201",
   "metadata": {},
   "source": [
    "### Defining basic variables for export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b9801d-9143-4eb8-81e9-718cd2da843f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ONNX_convert_params = step_params[\"ONNX_convert_params\"]\n",
    "DEVICE              = ONNX_convert_params[\"device\"]\n",
    "OPSET_VERSION       = ONNX_convert_params[\"opset_version\"]\n",
    "VERBOSE             = ONNX_convert_params[\"verbose\"]\n",
    "\n",
    "INPUT_NAMES  = ['input']\n",
    "OUTPUT_NAMES = ['output']\n",
    "DYNAMIC_AXES = {'input':\n",
    "                {0: 'batch',\n",
    "                 2: 'height',\n",
    "                 3: 'width'},\n",
    "                'output': \n",
    "                {0: 'batch'}\n",
    "               }\n",
    "\n",
    "KEEP_INITIALIZERS_AS_INPUTS = False\n",
    "EXPORT_PARAMS               = True\n",
    "\n",
    "\n",
    "test_image_path = osp.join(tmp_entities.classifier_inference_files, \"test.png\")\n",
    "test_image = cv2.imread(test_image_path)\n",
    "INPUT_SIZE = test_image.shape[:2]\n",
    "\n",
    "with open(osp.join(tmp_entities.meta_cifar10_datasets, 'meta_cifar10_datasets.json'), 'r') as f:\n",
    "   CATEGORIES = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9163ed47-36ee-4bda-b4a7-6a9c92754f55",
   "metadata": {},
   "source": [
    "#### Loading torch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c55f386-85dd-4c67-b6e3-6cde0f54d92b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_classifier = torch.load(selected_weights_pth, map_location=torch.device(DEVICE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e3c780-f2ff-42a6-9ce0-197928f54025",
   "metadata": {},
   "source": [
    "#### Converting to onnx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29e2a5e-4744-4151-9034-3d648817e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = np.zeros([1, 3, INPUT_SIZE[0], INPUT_SIZE[1]], dtype=np.float32)  # image zeros by shape [height, width, chanels]\n",
    "dummy_input = torch.Tensor(dummy_input).to(DEVICE)\n",
    "\n",
    "out_onnx_filename = osp.basename(selected_weights_pth).replace(\".pth\", \".onnx\")\n",
    "out_onnx_filepath = osp.join(tmp_entities.classifier_onnx_files, out_onnx_filename)\n",
    "\n",
    "torch.onnx.export(net_classifier,\n",
    "                  dummy_input,\n",
    "                  out_onnx_filepath,\n",
    "                  verbose=VERBOSE,\n",
    "                  input_names=INPUT_NAMES,\n",
    "                  output_names=OUTPUT_NAMES,\n",
    "                  dynamic_axes=DYNAMIC_AXES,\n",
    "                  export_params=EXPORT_PARAMS,\n",
    "                  keep_initializers_as_inputs=KEEP_INITIALIZERS_AS_INPUTS\n",
    "                 )        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "552a0af3-4074-4a5b-a4f6-42ef98e7387d",
   "metadata": {},
   "source": [
    "### Pack to REST BentoService"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47bf3ef-76b7-4312-ac09-b6c79cf06b44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bento_service import ModelService\n",
    "from pre_post_processing import PrePostProcessing\n",
    "\n",
    "# CATEGORIES = [{\"id\": class_id+1, \"name\": class_name} for class_id, class_name in enumerate(CLASSES)]\n",
    "\n",
    "outputs = substep.outputs()\n",
    "\n",
    "# copy test image \n",
    "test_image_path = osp.join(tmp_entities.classifier_inference_files, \"test.png\")\n",
    "onnx_test_image_path =  osp.join(tmp_entities.classifier_onnx_files, \"test.png\")\n",
    "shutil.copy(test_image_path, onnx_test_image_path)\n",
    "if not osp.exists(onnx_test_image_path):\n",
    "    raise FileNotFoundError(f\"{onnx_test_image_path} was not found\")\n",
    "    \n",
    "# inicialize onnx model\n",
    "onnx_file = os.path.join(tmp_entities.classifier_onnx_files, out_onnx_filename)\n",
    "if not osp.exists(onnx_file):\n",
    "    raise FileNotFoundError(f\"{onnx_file} was not found\")\n",
    "    \n",
    "ort_session = onnxruntime.InferenceSession(onnx_file, providers=['CPUExecutionProvider'])\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "output_name = [out.name for out in ort_session.get_outputs()]\n",
    "\n",
    "# read test image and processing for inference by onnx\n",
    "pre_post_processing = PrePostProcessing()\n",
    "input_data = pre_post_processing.prep_processing(onnx_test_image_path, input_size=INPUT_SIZE)\n",
    "# inference onnx by test image\n",
    "outs = ort_session.run(output_name, {input_name: input_data})\n",
    "outs = pre_post_processing.post_processing(outs, categories=CATEGORIES)\n",
    "\n",
    "# save and reopen pickle file output of inference by test image\n",
    "with open(osp.join(tmp_entities.classifier_onnx_files, 'test_result.pkl'), 'wb') as pkl_file:\n",
    "    pickle.dump(outs, pkl_file)    \n",
    "with open(osp.join(tmp_entities.classifier_onnx_files, 'test_result.pkl'), 'rb') as f_id:\n",
    "    test_result = f_id.read()    \n",
    "    \n",
    "# open test image\n",
    "with open(onnx_test_image_path, 'rb') as f_id:\n",
    "    test_image = f_id.read()   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51a4e94-24bd-45aa-801f-f45be444a118",
   "metadata": {},
   "source": [
    "#### Packaging obj_detector files to bento_service artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e43b1b2-eef4-426a-aa14-1ab4b0af46f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_service = ModelService()\n",
    "model_service.pack('model', onnx_file)\n",
    "model_service.pack('test_image', test_image)\n",
    "model_service.pack('test_result', test_result)    \n",
    "model_service.pack('categories', CATEGORIES)\n",
    "model_service.pack('input_size', INPUT_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4dde87-41ce-48cc-984f-5f5099d6d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_service.predict(onnx_test_image_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41b3171-c23d-4bff-83da-96a4900ca2e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Send packaged onnx_obj_detector to outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9fe07f-fcd5-4d03-886b-dbdf4b60db64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# save model as a bento pack\n",
    "from sinara.bentoml import save_bentoservice\n",
    "save_bentoservice(model_service, path=outputs.bento_service, substep=substep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b6aec1-7ca6-40b7-965e-07da5ee26b70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# stop spark\n",
    "SinaraSpark.stop_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc6037-4470-4f64-b481-336a2e67a4f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
